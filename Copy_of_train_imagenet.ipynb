{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JayaShreeGit/CS579/blob/master/Copy_of_train_imagenet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6b0fc7c3",
      "metadata": {
        "id": "6b0fc7c3"
      },
      "source": [
        "# Randomized Smoothing Training - ImageNet Edition\n",
        "\n",
        "This notebook trains image classifiers with randomized smoothing for provable adversarial robustness on **ImageNet** dataset.\n",
        "\n",
        "**Note:** CIFAR-100 code is preserved as comments. You can switch between datasets by commenting/uncommenting the appropriate sections.\n",
        "\n",
        "**Setup Instructions:**\n",
        "1. Ensure ImageNet dataset is available in the specified directory (or uncomment CIFAR-100 sections)\n",
        "2. Run all cells in order\n",
        "\n",
        "3. Training will run on GPU (recommended)4. ImageNet requires significant storage (~150GB) and compute resources"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dd4de696",
      "metadata": {
        "id": "dd4de696"
      },
      "source": [
        "## Step 0: Check GPU and Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3c8f4e97",
      "metadata": {
        "id": "3c8f4e97"
      },
      "outputs": [],
      "source": [
        "# Check GPU availability\n",
        "!nvidia-smi\n",
        "\n",
        "# Install required packages\n",
        "!pip install -q torch torchvision\n",
        "!pip install -q kaggle\n",
        "!pip install -q pandas matplotlib\n",
        "\n",
        "import torch\n",
        "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA version: {torch.version.cuda}\")\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "af5d6ccd",
      "metadata": {
        "id": "af5d6ccd"
      },
      "source": [
        "## Step 1: Setup ImageNet Dataset Path\n",
        "\n",
        "Configure the path to your ImageNet dataset. The dataset should be organized in train/val folders."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "db3a89fd",
      "metadata": {
        "id": "db3a89fd"
      },
      "outputs": [],
      "source": [
        "# Configure Kaggle API credentials using uploaded kaggle.json token file\n",
        "import os\n",
        "import json\n",
        "\n",
        "# Option 1: Upload kaggle.json file (Recommended)\n",
        "# Click the file upload icon in Colab and upload your kaggle.json file\n",
        "from google.colab import files\n",
        "\n",
        "print(\"Please upload your kaggle.json file...\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "if 'kaggle.json' in uploaded:\n",
        "    # Create .kaggle directory\n",
        "    os.makedirs('/root/.kaggle', exist_ok=True)\n",
        "\n",
        "    # Save the uploaded file\n",
        "    with open('/root/.kaggle/kaggle.json', 'w') as f:\n",
        "        f.write(uploaded['kaggle.json'].decode('utf-8'))\n",
        "\n",
        "    # Set proper permissions\n",
        "    os.chmod('/root/.kaggle/kaggle.json', 0o600)\n",
        "\n",
        "    # Load credentials into environment\n",
        "    with open('/root/.kaggle/kaggle.json', 'r') as f:\n",
        "        kaggle_creds = json.load(f)\n",
        "        os.environ['KAGGLE_USERNAME'] = kaggle_creds['username']\n",
        "        os.environ['KAGGLE_KEY'] = kaggle_creds['key']\n",
        "\n",
        "    print(\"‚úì Kaggle credentials configured successfully!\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No kaggle.json file uploaded. Please upload it to continue.\")\n",
        "\n",
        "# Option 2: Manual entry (Commented out - Uncomment if you prefer manual entry)\n",
        "# from google.colab import userdata\n",
        "# os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
        "# os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
        "# print(\"‚úì Kaggle credentials configured from Colab Secrets\")\n",
        "\n",
        "# Download ImageNet dataset from Kaggle\n",
        "print(\"\\nDownloading ImageNet dataset from Kaggle...\")\n",
        "print(\"Dataset: aryankaushik005/imagenet\")\n",
        "print(\"This may take some time depending on dataset size...\")\n",
        "\n",
        "!kaggle datasets download -d aryankaushik005/imagenet\n",
        "!mkdir -p /content/imagenet\n",
        "!unzip -q imagenet.zip -d /content/imagenet\n",
        "\n",
        "print(\"‚úì Dataset downloaded and extracted\")\n",
        "\n",
        "# Set ImageNet path - check multiple possible structures\n",
        "imagenet_path = '/content/imagenet'\n",
        "\n",
        "# Check for different possible directory structures\n",
        "possible_paths = [\n",
        "    '/content/imagenet/train',\n",
        "    '/content/imagenet/ILSVRC/Data/CLS-LOC',\n",
        "    '/content/imagenet/imagenet/train',\n",
        "    '/content/imagenet'\n",
        "]\n",
        "\n",
        "# Find the correct path\n",
        "for path in possible_paths:\n",
        "    if os.path.exists(os.path.join(path, 'train')) and os.path.exists(os.path.join(path, 'val')):\n",
        "        imagenet_path = path\n",
        "        break\n",
        "    elif path == '/content/imagenet' and os.path.exists(path):\n",
        "        # Check if train/val are directly in /content/imagenet\n",
        "        if os.path.exists(os.path.join(path, 'train')):\n",
        "            imagenet_path = path\n",
        "            break\n",
        "\n",
        "print(f\"\\nImageNet dataset path: {imagenet_path}\")\n",
        "print(f\"Train path: {os.path.join(imagenet_path, 'train')}\")\n",
        "print(f\"Val path: {os.path.join(imagenet_path, 'val')}\")\n",
        "\n",
        "if os.path.exists(os.path.join(imagenet_path, 'train')):\n",
        "    print(\"‚úì ImageNet path verified\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Warning: ImageNet structure not found. Checking directory contents...\")\n",
        "    print(\"\\nDirectory structure:\")\n",
        "    !ls -la /content/imagenet\n",
        "\n",
        "\n",
        "# ===== Alternative Options (Commented Out) =====\n",
        "\n",
        "# Option 2: Use ImageNet-Mini (1000 classes, ~25GB)\n",
        "# !kaggle datasets download -d ifigotin/imagenetmini-1000\n",
        "# !mkdir -p /content/imagenet\n",
        "# !unzip -q imagenetmini-1000.zip -d /content/imagenet\n",
        "# imagenet_path = '/content/imagenet/imagenet-mini'\n",
        "\n",
        "# Option 3: Use Tiny-ImageNet (200 classes, 64x64 images, ~500MB)\n",
        "# !wget http://cs231n.stanford.edu/tiny-imagenet-200.zip\n",
        "# !unzip -q tiny-imagenet-200.zip -d /content/\n",
        "# imagenet_path = '/content/tiny-imagenet-200'\n",
        "\n",
        "# Option 4: Use CIFAR-100 (100 classes, 32x32, ~600MB, auto-download)\n",
        "# See commented sections below for CIFAR-100 configuration\n",
        "\n",
        "# Option 5: Local Machine Path\n",
        "# imagenet_path = r'c:\\Users\\jayas\\Documents\\PhD\\random_smoothing\\datasets\\imagenet'\n",
        "\n",
        "# ===== CIFAR-100 Configuration (Commented Out) =====\n",
        "# print(\"‚úì CIFAR-100 will be downloaded automatically using torchvision\")\n",
        "# # CIFAR-100 will be downloaded automatically - no path needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ec52516f",
      "metadata": {
        "id": "ec52516f"
      },
      "outputs": [],
      "source": [
        "# ===== ImageNet Verification (Active) =====\n",
        "print(\"Verifying ImageNet dataset structure...\")\n",
        "\n",
        "train_path = os.path.join(imagenet_path, 'train')\n",
        "val_path = os.path.join(imagenet_path, 'val')\n",
        "\n",
        "if os.path.exists(train_path):\n",
        "    train_dirs = [d for d in os.listdir(train_path) if os.path.isdir(os.path.join(train_path, d))]\n",
        "    print(f\"‚úì Train directory found with {len(train_dirs)} class folders\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Train directory not found\")\n",
        "\n",
        "if os.path.exists(val_path):\n",
        "    val_dirs = [d for d in os.listdir(val_path) if os.path.isdir(os.path.join(val_path, d))]\n",
        "    print(f\"‚úì Val directory found with {len(val_dirs)} class folders\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Val directory not found\")\n",
        "\n",
        "print(\"\\nNote: ImageNet should have 1000 class folders in both train and val directories\")\n",
        "\n",
        "# print(\"CIFAR-100 will be downloaded automatically in the next cell\")\n",
        "\n",
        "# ===== CIFAR-100 Verification (Commented Out) =====# # No verification needed - dataset downloads automatically"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "65f8ca02",
      "metadata": {
        "id": "65f8ca02"
      },
      "source": [
        "## Step 2: Clone Repository and Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0be2b657",
      "metadata": {
        "id": "0be2b657"
      },
      "outputs": [],
      "source": [
        "# Clone the randomized smoothing repository\n",
        "!git clone https://github.com/JayaShreeGit/random_smoothing.git /content/random_smoothing\n",
        "\n",
        "# Navigate to code directory\n",
        "import os\n",
        "os.chdir('/content/random_smoothing/code')\n",
        "\n",
        "print(f\"‚úì Repository cloned\")\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(f\"\\nCode files:\")\n",
        "!ls -lh *.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c10bf550",
      "metadata": {
        "id": "c10bf550"
      },
      "outputs": [],
      "source": [
        "# Create output directory for models\n",
        "import os\n",
        "\n",
        "# ===== ImageNet Output Directory (Active) =====\n",
        "outdir = r'c:\\Users\\jayas\\Documents\\PhD\\random_smoothing\\models\\imagenet\\resnet18\\noise_0.25'\n",
        "\n",
        "# ===== CIFAR-100 Output Directory (Commented Out) =====\n",
        "\n",
        "# outdir = r'c:\\Users\\jayas\\Documents\\PhD\\random_smoothing\\models\\cifar100\\resnet\\noise_0.25'print(f\"‚úì Model directory created: {outdir}\")\n",
        "\n",
        "os.makedirs(outdir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "452cc0ba",
      "metadata": {
        "id": "452cc0ba"
      },
      "source": [
        "## Step 3: Load ImageNet Dataset\n",
        "\n",
        "Load the ImageNet dataset using PyTorch's ImageFolder. ImageNet images are 224√ó224 with 1000 classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f686817a",
      "metadata": {
        "id": "f686817a"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "# from torchvision.datasets import CIFAR100  # Uncomment for CIFAR-100\n",
        "\n",
        "# ===== ImageNet Dataset Loading (Active) =====\n",
        "print(\"Loading ImageNet dataset...\")\n",
        "print(\"This may take a moment due to the large number of images.\")\n",
        "\n",
        "# ImageNet normalization values\n",
        "imagenet_mean = (0.485, 0.456, 0.406)\n",
        "imagenet_std = (0.229, 0.224, 0.225)\n",
        "\n",
        "# Define transforms for training data (with augmentation)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])\n",
        "\n",
        "# Define transforms for validation data (no augmentation)\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(imagenet_mean, imagenet_std)\n",
        "])\n",
        "\n",
        "# Load datasets using ImageFolder\n",
        "train_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(imagenet_path, 'train'),\n",
        "    transform=train_transform\n",
        ")\n",
        "\n",
        "test_dataset = datasets.ImageFolder(\n",
        "    root=os.path.join(imagenet_path, 'val'),\n",
        "    transform=val_transform\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úì ImageNet dataset loaded successfully!\")\n",
        "print(f\"Training samples: {len(train_dataset):,}\")\n",
        "print(f\"Validation samples: {len(test_dataset):,}\")\n",
        "\n",
        "print(f\"Number of classes: {len(train_dataset.classes)}\")# print(f\"Image size: 32√ó32√ó3\")\n",
        "\n",
        "print(f\"Image size: 224√ó224√ó3\")# print(f\"Number of classes: 100\")\n",
        "\n",
        "# print(f\"Test samples: {len(test_dataset):,}\")\n",
        "\n",
        "# ===== CIFAR-100 Dataset Loading (Commented Out) =====# print(f\"Training samples: {len(train_dataset):,}\")\n",
        "\n",
        "# print(\"Loading CIFAR-100 dataset...\")# print(f\"\\n‚úì CIFAR-100 dataset loaded successfully!\")\n",
        "\n",
        "# print(\"This will automatically download the dataset if not already present.\")#\n",
        "\n",
        "# #                        download=True, transform=test_transform)\n",
        "\n",
        "# # CIFAR-100 normalization values# test_dataset = CIFAR100(root='./data/cifar100', train=False,\n",
        "\n",
        "# cifar100_mean = (0.5071, 0.4867, 0.4408)#                         download=True, transform=train_transform)\n",
        "\n",
        "# cifar100_std = (0.2675, 0.2565, 0.2761)# train_dataset = CIFAR100(root='./data/cifar100', train=True,\n",
        "\n",
        "# # # Download and create datasets\n",
        "\n",
        "# # Define transforms for training data (with augmentation)#\n",
        "\n",
        "# train_transform = transforms.Compose([# ])\n",
        "\n",
        "#     transforms.RandomCrop(32, padding=4),#     transforms.Normalize(cifar100_mean, cifar100_std)\n",
        "\n",
        "#     transforms.RandomHorizontalFlip(),#     transforms.ToTensor(),\n",
        "\n",
        "#     transforms.ToTensor(),# test_transform = transforms.Compose([\n",
        "\n",
        "#     transforms.Normalize(cifar100_mean, cifar100_std)# # Define transforms for test data (no augmentation)\n",
        "\n",
        "# ])#"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c96d032f",
      "metadata": {
        "id": "c96d032f"
      },
      "source": [
        "## Step 4: Import Training Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c00d4d6",
      "metadata": {
        "id": "6c00d4d6"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import SGD, Optimizer\n",
        "from torch.optim.lr_scheduler import StepLR\n",
        "from torchvision import models, transforms\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "print(f\"‚úì Libraries imported\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5603339",
      "metadata": {
        "id": "b5603339"
      },
      "source": [
        "## Step 5: Configure Training Parameters\n",
        "\n",
        "Configure hyperparameters for ImageNet with randomized smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6a33dbd5",
      "metadata": {
        "id": "6a33dbd5"
      },
      "outputs": [],
      "source": [
        "# ===== ImageNet Configuration (Active) =====\n",
        "class Config:\n",
        "    def __init__(self):\n",
        "        # Dataset parameters\n",
        "        self.dataset = 'imagenet'\n",
        "        self.num_classes = 1000\n",
        "        self.image_size = 224\n",
        "\n",
        "        # Model architecture (using ResNet-18 for ImageNet)\n",
        "        self.arch = 'resnet18'\n",
        "\n",
        "        # Output directory\n",
        "        self.outdir = outdir\n",
        "\n",
        "        # Training hyperparameters (standard ImageNet settings)\n",
        "        self.batch = 256  # Adjust based on GPU memory (use 128 or 64 if OOM)\n",
        "        self.epochs = 50\n",
        "        self.lr = 0.1\n",
        "        self.lr_step_size = 20\n",
        "        self.gamma = 0.1\n",
        "        self.momentum = 0.9\n",
        "        self.weight_decay = 1e-4\n",
        "\n",
        "        # Randomized smoothing noise\n",
        "        self.noise_sd = 0.0  # Standard deviation of Gaussian noise\n",
        "\n",
        "        # System parameters\n",
        "        self.workers = 4  # Adjust based on CPU cores\n",
        "        self.print_freq = 100\n",
        "\n",
        "args = Config()\n",
        "\n",
        "print(\"‚úì Training configuration:\")\n",
        "print(f\"  Dataset: ImageNet (1000 classes)\")\n",
        "print(f\"  Architecture: {args.arch}\")\n",
        "print(f\"  Noise œÉ: {args.noise_sd}\")\n",
        "print(f\"  Batch size: {args.batch}\")\n",
        "print(f\"  Epochs: {args.epochs}\")\n",
        "print(f\"  Image size: {args.image_size}√ó{args.image_size}\")\n",
        "print(f\"  Output directory: {args.outdir}\")\n",
        "\n",
        "# print(f\"  Output directory: {args.outdir}\")\n",
        "\n",
        "# ===== CIFAR-100 Configuration (Commented Out) =====# print(f\"  Epochs: {args.epochs}\")\n",
        "\n",
        "# class Config:# print(f\"  Batch size: {args.batch}\")\n",
        "\n",
        "#     def __init__(self):# print(f\"  Noise œÉ: {args.noise_sd}\")\n",
        "\n",
        "#         # Dataset parameters# print(f\"  Architecture: {args.arch}\")\n",
        "\n",
        "#         self.dataset = 'cifar100'# print(f\"  Dataset: CIFAR-100 (100 classes)\")\n",
        "\n",
        "#         self.num_classes = 100# print(\"‚úì Training configuration:\")\n",
        "\n",
        "#         self.image_size = 32#\n",
        "\n",
        "#         # args = Config()\n",
        "\n",
        "#         # Model architecture (using ResNet-18 for CIFAR-100)#\n",
        "\n",
        "#         self.arch = 'resnet18'#         self.print_freq = 50\n",
        "\n",
        "#         #         self.workers = 2  # Fewer workers for smaller dataset\n",
        "\n",
        "#         # Output directory#         # System parameters\n",
        "\n",
        "#         self.outdir = outdir#\n",
        "\n",
        "#         #         self.noise_sd = 0.25  # Standard deviation of Gaussian noise\n",
        "\n",
        "#         # Training hyperparameters#         # Randomized smoothing noise\n",
        "\n",
        "#         self.batch = 128  # Smaller batch for CIFAR-100#\n",
        "\n",
        "#         self.epochs = 90#         self.weight_decay = 1e-4\n",
        "\n",
        "#         self.lr = 0.1#         self.momentum = 0.9\n",
        "\n",
        "#         self.lr_step_size = 30#         self.gamma = 0.1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca95ccf0",
      "metadata": {
        "id": "ca95ccf0"
      },
      "source": [
        "## Step 6: Create Data Loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aaf23da8",
      "metadata": {
        "id": "aaf23da8"
      },
      "outputs": [],
      "source": [
        "# Create data loaders (datasets already created in previous cell)\n",
        "train_loader = DataLoader(train_dataset, batch_size=args.batch,\n",
        "                         shuffle=True, num_workers=args.workers, pin_memory=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=args.batch,\n",
        "                        shuffle=False, num_workers=args.workers, pin_memory=True)\n",
        "\n",
        "print(f\"‚úì Data loaders created\")\n",
        "print(f\"Training batches: {len(train_loader)}\")\n",
        "print(f\"Test batches: {len(test_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7049116c",
      "metadata": {
        "id": "7049116c"
      },
      "source": [
        "## Step 7: Initialize Model and Training Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59657ac7",
      "metadata": {
        "id": "59657ac7"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# ===== ImageNet Model (Active) =====\n",
        "# Initialize ResNet-50 for ImageNet\n",
        "model = models.resnet18(pretrained=False)\n",
        "# The model already has 1000 classes by default, which matches ImageNet\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "# ===== CIFAR-100 Model (Commented Out) =====\n",
        "# # Initialize ResNet-18 for CIFAR-100\n",
        "# model = models.resnet18(pretrained=False)\n",
        "# # Modify first conv layer for 32x32 images\n",
        "# model.conv1 = torch.nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1, bias=False)\n",
        "# model.maxpool = torch.nn.Identity()  # Remove maxpool for small images\n",
        "# # Modify final layer for 100 classes\n",
        "# model.fc = torch.nn.Linear(model.fc.in_features, args.num_classes)\n",
        "#\n",
        "# model = model.to(device)\n",
        "\n",
        "# Count parameters\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"‚úì Model initialized: {args.arch}\")\n",
        "print(f\"Total parameters: {total_params:,}\")\n",
        "print(f\"Trainable parameters: {trainable_params:,}\")\n",
        "\n",
        "print(f\"Device: {device}\")\n",
        "\n",
        "# Loss function, optimizer, and scheduler\n",
        "criterion = CrossEntropyLoss().to(device)\n",
        "\n",
        "optimizer = SGD(model.parameters(), lr=args.lr, momentum=args.momentum,\n",
        "                weight_decay=args.weight_decay)\n",
        "scheduler = StepLR(optimizer, step_size=args.lr_step_size, gamma=args.gamma)\n",
        "\n",
        "print(f\"Optimizer: SGD (lr={args.lr}, momentum={args.momentum}, weight_decay={args.weight_decay})\")\n",
        "print(f\"Scheduler: StepLR (step={args.lr_step_size}, gamma={args.gamma})\")\n",
        "print(f\"\\n‚úì Training components initialized\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "20e32b18",
      "metadata": {
        "id": "20e32b18"
      },
      "source": [
        "## Step 8: Define Training and Testing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00d88d18",
      "metadata": {
        "id": "00d88d18"
      },
      "outputs": [],
      "source": [
        "def accuracy(output, target, topk=(1,)):\n",
        "    \"\"\"Computes the accuracy over the k top predictions\"\"\"\n",
        "    with torch.no_grad():\n",
        "        maxk = max(topk)\n",
        "        batch_size = target.size(0)\n",
        "\n",
        "        _, pred = output.topk(maxk, 1, True, True)\n",
        "        pred = pred.t()\n",
        "        correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
        "\n",
        "        res = []\n",
        "        for k in topk:\n",
        "            correct_k = correct[:k].reshape(-1).float().sum(0, keepdim=True)\n",
        "            res.append(correct_k.mul_(100.0 / batch_size))\n",
        "        return res\n",
        "\n",
        "def train_epoch(loader, model, criterion, optimizer, epoch, noise_sd):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        # Add Gaussian noise for randomized smoothing\n",
        "        inputs = inputs + torch.randn_like(inputs) * noise_sd\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "        if batch_idx % args.print_freq == 0:\n",
        "            print(f'Epoch: {epoch} [{batch_idx}/{len(loader)}] '\n",
        "                  f'Loss: {train_loss/(batch_idx+1):.3f} | '\n",
        "                  f'Acc: {100.*correct/total:.2f}% ({correct}/{total})')\n",
        "\n",
        "    return train_loss/len(loader), 100.*correct/total\n",
        "\n",
        "def test_epoch(loader, model, criterion, noise_sd):\n",
        "    \"\"\"Evaluate on test set\"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Add Gaussian noise\n",
        "            inputs = inputs + torch.randn_like(inputs) * noise_sd\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    return test_loss/len(loader), 100.*correct/total\n",
        "\n",
        "print(\"‚úì Training and testing functions defined\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b911042f",
      "metadata": {
        "id": "b911042f"
      },
      "source": [
        "## Step 9: Run Training Loop\n",
        "\n",
        "Train the model for all epochs with randomized smoothing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8662b030",
      "metadata": {
        "id": "8662b030"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "# Create log file\n",
        "os.makedirs(args.outdir, exist_ok=True)\n",
        "logfile = os.path.join(args.outdir, 'training_log.txt')\n",
        "\n",
        "with open(logfile, 'w') as f:\n",
        "    f.write('epoch\\ttime\\tlr\\ttrain_loss\\ttrain_acc\\ttest_loss\\ttest_acc\\n')\n",
        "\n",
        "print(f\"Starting training for {args.epochs} epochs...\")\n",
        "print(f\"Noise œÉ = {args.noise_sd}\")\n",
        "print(f\"Log file: {logfile}\\n\")\n",
        "\n",
        "# Training history\n",
        "history = {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "\n",
        "for epoch in range(args.epochs):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train\n",
        "    train_loss, train_acc = train_epoch(train_loader, model, criterion,\n",
        "                                       optimizer, epoch, args.noise_sd)\n",
        "\n",
        "    # Test\n",
        "    test_loss, test_acc = test_epoch(test_loader, model, criterion, args.noise_sd)\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    epoch_time = time.time() - start_time\n",
        "\n",
        "    # Save history\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['train_acc'].append(train_acc)\n",
        "    history['test_loss'].append(test_loss)\n",
        "    history['test_acc'].append(test_acc)\n",
        "\n",
        "    # Log results\n",
        "    with open(logfile, 'a') as f:\n",
        "        f.write(f'{epoch}\\t{epoch_time:.1f}\\t{scheduler.get_last_lr()[0]:.6f}\\t'\n",
        "                f'{train_loss:.4f}\\t{train_acc:.2f}\\t{test_loss:.4f}\\t{test_acc:.2f}\\n')\n",
        "\n",
        "    print(f'\\n=== Epoch {epoch}/{args.epochs} Summary ===')\n",
        "    print(f'Time: {epoch_time:.1f}s | LR: {scheduler.get_last_lr()[0]:.6f}')\n",
        "    print(f'Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%')\n",
        "    print(f'Test Loss: {test_loss:.4f} | Test Acc: {test_acc:.2f}%\\n')\n",
        "\n",
        "    # Save checkpoint\n",
        "    torch.save({\n",
        "        'epoch': epoch,\n",
        "        'model_state_dict': model.state_dict(),\n",
        "        'optimizer_state_dict': optimizer.state_dict(),\n",
        "        'train_acc': train_acc,\n",
        "        'test_acc': test_acc,\n",
        "    }, os.path.join(args.outdir, 'checkpoint.pth'))\n",
        "\n",
        "print(\"\\n‚úì Training complete!\")\n",
        "print(f\"Final Test Accuracy: {history['test_acc'][-1]:.2f}%\")\n",
        "print(f\"Model saved to: {args.outdir}/checkpoint.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cacfb8e",
      "metadata": {
        "id": "5cacfb8e"
      },
      "source": [
        "## Step 10: Visualize Training Results\n",
        "\n",
        "Plot training and testing curves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "59f1b91c",
      "metadata": {
        "id": "59f1b91c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "epochs = range(len(history['train_loss']))\n",
        "\n",
        "# Loss plot\n",
        "ax1.plot(epochs, history['train_loss'], 'b-', label='Train Loss', linewidth=2)\n",
        "ax1.plot(epochs, history['test_loss'], 'r-', label='Test Loss', linewidth=2)\n",
        "ax1.set_xlabel('Epoch', fontsize=12)\n",
        "ax1.set_ylabel('Loss', fontsize=12)\n",
        "ax1.set_title('Training and Test Loss', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy plot\n",
        "ax2.plot(epochs, history['train_acc'], 'b-', label='Train Accuracy', linewidth=2)\n",
        "ax2.plot(epochs, history['test_acc'], 'r-', label='Test Accuracy', linewidth=2)\n",
        "ax2.set_xlabel('Epoch', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax2.set_title('Training and Test Accuracy', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(args.outdir, 'training_curves.png'), dpi=150, bbox_inches='tight')\n",
        "print(f\"‚úì Training curves saved to {args.outdir}/training_curves.png\")\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"\\n=== Training Summary ===\")\n",
        "print(f\"Best Train Accuracy: {max(history['train_acc']):.2f}% (Epoch {history['train_acc'].index(max(history['train_acc']))})\")\n",
        "print(f\"Best Test Accuracy: {max(history['test_acc']):.2f}% (Epoch {history['test_acc'].index(max(history['test_acc']))})\")\n",
        "print(f\"Final Train Accuracy: {history['train_acc'][-1]:.2f}%\")\n",
        "print(f\"Final Test Accuracy: {history['test_acc'][-1]:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9d36c310",
      "metadata": {
        "id": "9d36c310"
      },
      "source": [
        "## Next Steps\n",
        "\n",
        "Your CIFAR-100 model with randomized smoothing is now trained!\n",
        "\n",
        "**What you can do next:**\n",
        "\n",
        "1. **Download the trained model:**\n",
        "   ```python\n",
        "   from google.colab import files\n",
        "   files.download('/content/models/cifar100/resnet/noise_0.25/checkpoint.pth')\n",
        "   ```\n",
        "\n",
        "2. **Test on individual images:**\n",
        "   - Load your model and test on custom CIFAR-100 images\n",
        "   - Visualize certified regions around test samples\n",
        "\n",
        "3. **Experiment with different noise levels:**\n",
        "   - Change `args.noise_sd` to 0.0, 0.12, 0.50, or 1.0\n",
        "   - Compare robustness vs accuracy trade-offs\n",
        "\n",
        "4. **Try different architectures:**\n",
        "   - Replace ResNet-18 with ResNet-34, ResNet-50, or other architectures\n",
        "   - Adjust for different robustness requirements\n",
        "\n",
        "**Key Results:**\n",
        "- Model trained on CIFAR-100 (100 classes)\n",
        "- Randomized smoothing noise œÉ = 0.25\n",
        "- Provides provable adversarial robustness guarantees"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a98a1e55",
      "metadata": {
        "id": "a98a1e55"
      },
      "source": [
        "## Step 11: Load Trained Model for Evaluation\n",
        "\n",
        "Load the trained model checkpoint to evaluate its performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e1d3eda3",
      "metadata": {
        "id": "e1d3eda3"
      },
      "outputs": [],
      "source": [
        "# Load the trained model checkpoint\n",
        "checkpoint_path = os.path.join(args.outdir, 'checkpoint.pth')\n",
        "\n",
        "if os.path.exists(checkpoint_path):\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    print(f\"‚úì Model loaded from: {checkpoint_path}\")\n",
        "    print(f\"  Trained for {checkpoint['epoch']} epochs\")\n",
        "    print(f\"  Final train accuracy: {checkpoint['train_acc']:.2f}%\")\n",
        "    print(f\"  Final test accuracy: {checkpoint['test_acc']:.2f}%\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è No checkpoint found. Please train the model first.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2294aff6",
      "metadata": {
        "id": "2294aff6"
      },
      "source": [
        "## Step 12: Comprehensive Model Evaluation\n",
        "\n",
        "Evaluate the model with detailed metrics including per-class accuracy, confusion matrix, and robustness analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "65aa1340",
      "metadata": {
        "id": "65aa1340"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_recall_fscore_support\n",
        "import time\n",
        "\n",
        "def evaluate_model_detailed(model, loader, noise_sd, device):\n",
        "    \"\"\"\n",
        "    Comprehensive evaluation with detailed metrics.\n",
        "\n",
        "    Returns:\n",
        "        Dictionary containing various performance metrics\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "    all_probs = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    inference_times = []\n",
        "\n",
        "    print(\"Evaluating model...\")\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (inputs, targets) in enumerate(loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Measure inference time\n",
        "            start_time = time.time()\n",
        "\n",
        "            # Add Gaussian noise for randomized smoothing\n",
        "            inputs = inputs + torch.randn_like(inputs) * noise_sd\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            inference_times.append(time.time() - start_time)\n",
        "\n",
        "            # Get predictions\n",
        "            probs = torch.softmax(outputs, dim=1)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            # Store results\n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_probs.extend(probs.cpu().numpy())\n",
        "\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "            if batch_idx % 20 == 0:\n",
        "                print(f\"  Batch {batch_idx}/{len(loader)} processed...\")\n",
        "\n",
        "    # Calculate metrics\n",
        "    all_predictions = np.array(all_predictions)\n",
        "    all_targets = np.array(all_targets)\n",
        "    all_probs = np.array(all_probs)\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    avg_inference_time = np.mean(inference_times) * 1000  # Convert to ms\n",
        "\n",
        "    # Per-class metrics\n",
        "    precision, recall, f1, support = precision_recall_fscore_support(\n",
        "        all_targets, all_predictions, average=None, zero_division=0\n",
        "    )\n",
        "\n",
        "    # Overall metrics\n",
        "    macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
        "        all_targets, all_predictions, average='macro', zero_division=0\n",
        "    )\n",
        "\n",
        "    results = {\n",
        "        'accuracy': accuracy,\n",
        "        'correct': correct,\n",
        "        'total': total,\n",
        "        'avg_inference_time_ms': avg_inference_time,\n",
        "        'predictions': all_predictions,\n",
        "        'targets': all_targets,\n",
        "        'probabilities': all_probs,\n",
        "        'per_class_precision': precision,\n",
        "        'per_class_recall': recall,\n",
        "        'per_class_f1': f1,\n",
        "        'per_class_support': support,\n",
        "        'macro_precision': macro_precision,\n",
        "        'macro_recall': macro_recall,\n",
        "        'macro_f1': macro_f1\n",
        "    }\n",
        "\n",
        "    return results\n",
        "\n",
        "# Run evaluation\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"COMPREHENSIVE MODEL EVALUATION\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "\n",
        "eval_results = evaluate_model_detailed(model, test_loader, args.noise_sd, device)\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"EVALUATION RESULTS\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nüìä Overall Performance:\")\n",
        "print(f\"  Test Accuracy: {eval_results['accuracy']:.2f}%\")\n",
        "print(f\"  Correct Predictions: {eval_results['correct']}/{eval_results['total']}\")\n",
        "print(f\"  Macro Precision: {eval_results['macro_precision']:.4f}\")\n",
        "print(f\"  Macro Recall: {eval_results['macro_recall']:.4f}\")\n",
        "print(f\"  Macro F1-Score: {eval_results['macro_f1']:.4f}\")\n",
        "print(f\"\\n‚ö° Performance:\")\n",
        "print(f\"  Average Inference Time: {eval_results['avg_inference_time_ms']:.2f} ms per batch\")\n",
        "print(f\"  Throughput: {args.batch / (eval_results['avg_inference_time_ms']/1000):.1f} images/sec\")\n",
        "print(f\"\\nüîí Robustness:\")\n",
        "print(f\"  Gaussian Noise œÉ: {args.noise_sd}\")\n",
        "print(f\"  Certified Robustness: Model trained with randomized smoothing\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "196723c1",
      "metadata": {
        "id": "196723c1"
      },
      "source": [
        "## Step 13: Visualize Confusion Matrix\n",
        "\n",
        "Generate and visualize the confusion matrix to understand classification patterns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f2e4f82c",
      "metadata": {
        "id": "f2e4f82c"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Calculate confusion matrix\n",
        "cm = confusion_matrix(eval_results['targets'], eval_results['predictions'])\n",
        "\n",
        "# Create figure for confusion matrix\n",
        "fig, ax = plt.subplots(figsize=(12, 10))\n",
        "\n",
        "# Plot confusion matrix (showing only diagonal and major errors due to 100 classes)\n",
        "# We'll create a simplified view\n",
        "sns.heatmap(cm, cmap='Blues', cbar=True, square=True, ax=ax,\n",
        "            xticklabels=False, yticklabels=False)\n",
        "\n",
        "ax.set_xlabel('Predicted Label', fontsize=12)\n",
        "ax.set_ylabel('True Label', fontsize=12)\n",
        "ax.set_title(f'Confusion Matrix - ImageNet (1000 classes)\\nTest Accuracy: {eval_results[\"accuracy\"]:.2f}%',\n",
        "             fontsize=14, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(args.outdir, 'confusion_matrix.png'), dpi=150, bbox_inches='tight')\n",
        "print(f\"‚úì Confusion matrix saved to {args.outdir}/confusion_matrix.png\")\n",
        "plt.show()\n",
        "\n",
        "# Print top 10 most confused class pairs\n",
        "print(\"\\nüìã Top 10 Most Confused Class Pairs:\")\n",
        "print(f\"{'True Class':<12} {'Pred Class':<12} {'Count':<8} {'Error Rate'}\")\n",
        "print(\"-\" * 60)\n",
        "\n",
        "confused_pairs = []\n",
        "for i in range(1000):\n",
        "    for j in range(1000):\n",
        "        if i != j and cm[i, j] > 0:\n",
        "            error_rate = cm[i, j] / cm[i].sum() * 100\n",
        "            confused_pairs.append((i, j, cm[i, j], error_rate))\n",
        "\n",
        "confused_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "for true_class, pred_class, count, error_rate in confused_pairs[:10]:\n",
        "    print(f\"{true_class:<12} {pred_class:<12} {count:<8} {error_rate:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8d0359ab",
      "metadata": {
        "id": "8d0359ab"
      },
      "source": [
        "## Step 14: Per-Class Performance Analysis\n",
        "\n",
        "Analyze performance for each class to identify strengths and weaknesses."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28978873",
      "metadata": {
        "id": "28978873"
      },
      "outputs": [],
      "source": [
        "# Calculate per-class accuracy\n",
        "per_class_accuracy = []\n",
        "for i in range(1000):\n",
        "    mask = eval_results['targets'] == i\n",
        "    if mask.sum() > 0:\n",
        "        class_correct = (eval_results['predictions'][mask] == i).sum()\n",
        "        class_total = mask.sum()\n",
        "        per_class_accuracy.append(class_correct / class_total * 100)\n",
        "    else:\n",
        "        per_class_accuracy.append(0)\n",
        "\n",
        "per_class_accuracy = np.array(per_class_accuracy)\n",
        "\n",
        "# Print statistics\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"PER-CLASS PERFORMANCE STATISTICS\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "print(f\"Average per-class accuracy: {per_class_accuracy.mean():.2f}%\")\n",
        "print(f\"Std deviation: {per_class_accuracy.std():.2f}%\")\n",
        "print(f\"Min accuracy: {per_class_accuracy.min():.2f}% (Class {per_class_accuracy.argmin()})\")\n",
        "print(f\"Max accuracy: {per_class_accuracy.max():.2f}% (Class {per_class_accuracy.argmax()})\")\n",
        "print(f\"Median accuracy: {np.median(per_class_accuracy):.2f}%\")\n",
        "\n",
        "# Best and worst performing classes\n",
        "print(f\"\\nüèÜ Top 10 Best Performing Classes:\")\n",
        "print(f\"{'Class':<8} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score'}\")\n",
        "print(\"-\" * 60)\n",
        "best_classes = np.argsort(per_class_accuracy)[-10:][::-1]\n",
        "for cls in best_classes:\n",
        "    print(f\"{cls:<8} {per_class_accuracy[cls]:<12.2f} \"\n",
        "          f\"{eval_results['per_class_precision'][cls]:<12.4f} \"\n",
        "          f\"{eval_results['per_class_recall'][cls]:<12.4f} \"\n",
        "          f\"{eval_results['per_class_f1'][cls]:.4f}\")\n",
        "\n",
        "print(f\"\\n‚ö†Ô∏è Top 10 Worst Performing Classes:\")\n",
        "print(f\"{'Class':<8} {'Accuracy':<12} {'Precision':<12} {'Recall':<12} {'F1-Score'}\")\n",
        "print(\"-\" * 60)\n",
        "worst_classes = np.argsort(per_class_accuracy)[:10]\n",
        "for cls in worst_classes:\n",
        "    print(f\"{cls:<8} {per_class_accuracy[cls]:<12.2f} \"\n",
        "          f\"{eval_results['per_class_precision'][cls]:<12.4f} \"\n",
        "          f\"{eval_results['per_class_recall'][cls]:<12.4f} \"\n",
        "          f\"{eval_results['per_class_f1'][cls]:.4f}\")\n",
        "\n",
        "# Visualize per-class accuracy distribution\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "# Histogram\n",
        "ax1.hist(per_class_accuracy, bins=20, color='steelblue', edgecolor='black', alpha=0.7)\n",
        "ax1.axvline(per_class_accuracy.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {per_class_accuracy.mean():.2f}%')\n",
        "ax1.set_xlabel('Accuracy (%)', fontsize=12)\n",
        "ax1.set_ylabel('Number of Classes', fontsize=12)\n",
        "ax1.set_title('Distribution of Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
        "ax1.legend(fontsize=11)\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Sorted accuracy plot\n",
        "sorted_accuracy = np.sort(per_class_accuracy)\n",
        "ax2.plot(range(1000), sorted_accuracy, linewidth=2, color='steelblue')\n",
        "ax2.axhline(per_class_accuracy.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {per_class_accuracy.mean():.2f}%')\n",
        "ax2.fill_between(range(1000), sorted_accuracy, alpha=0.3, color='steelblue')\n",
        "ax2.set_xlabel('Class Rank', fontsize=12)\n",
        "ax2.set_ylabel('Accuracy (%)', fontsize=12)\n",
        "ax2.set_title('Sorted Per-Class Accuracy', fontsize=14, fontweight='bold')\n",
        "ax2.legend(fontsize=11)\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(args.outdir, 'per_class_accuracy.png'), dpi=150, bbox_inches='tight')\n",
        "print(f\"\\n‚úì Per-class accuracy visualization saved to {args.outdir}/per_class_accuracy.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a4bb5ec9",
      "metadata": {
        "id": "a4bb5ec9"
      },
      "source": [
        "## Step 15: Robustness Analysis - Compare Different Noise Levels\n",
        "\n",
        "Test the model's performance under different noise conditions to verify robustness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "71b014e5",
      "metadata": {
        "id": "71b014e5"
      },
      "outputs": [],
      "source": [
        "def test_robustness_at_noise_level(model, loader, noise_sd, device):\n",
        "    \"\"\"Test model accuracy at a specific noise level.\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Add noise\n",
        "            if noise_sd > 0:\n",
        "                inputs = inputs + torch.randn_like(inputs) * noise_sd\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, predicted = outputs.max(1)\n",
        "\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "    accuracy = 100. * correct / total\n",
        "    return accuracy\n",
        "\n",
        "# Test at different noise levels\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"ROBUSTNESS ANALYSIS - VARYING NOISE LEVELS\")\n",
        "print(f\"{'='*60}\\n\")\n",
        "print(f\"Model was trained with œÉ = {args.noise_sd}\\n\")\n",
        "\n",
        "noise_levels = [0.0, 0.12, 0.25, 0.50, 0.75, 1.0]\n",
        "accuracies = []\n",
        "\n",
        "print(f\"{'Noise œÉ':<12} {'Accuracy':<12} {'Degradation'}\")\n",
        "print(\"-\" * 50)\n",
        "\n",
        "for noise_sd in noise_levels:\n",
        "    acc = test_robustness_at_noise_level(model, test_loader, noise_sd, device)\n",
        "    accuracies.append(acc)\n",
        "\n",
        "    # Calculate degradation from no-noise baseline\n",
        "    degradation = accuracies[0] - acc if len(accuracies) > 1 else 0\n",
        "\n",
        "    marker = \"üìç\" if noise_sd == args.noise_sd else \"\"\n",
        "    print(f\"{noise_sd:<12.2f} {acc:<12.2f} {degradation:+.2f}%  {marker}\")\n",
        "\n",
        "# Visualize robustness curve\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "ax.plot(noise_levels, accuracies, marker='o', linewidth=2, markersize=8,\n",
        "        color='steelblue', label='Model Performance')\n",
        "ax.axvline(args.noise_sd, color='red', linestyle='--', linewidth=2,\n",
        "           label=f'Training Noise œÉ={args.noise_sd}')\n",
        "\n",
        "# Highlight training noise point\n",
        "train_noise_idx = noise_levels.index(args.noise_sd) if args.noise_sd in noise_levels else None\n",
        "if train_noise_idx is not None:\n",
        "    ax.scatter([args.noise_sd], [accuracies[train_noise_idx]],\n",
        "              color='red', s=200, zorder=5, alpha=0.7)\n",
        "\n",
        "ax.set_xlabel('Gaussian Noise Standard Deviation (œÉ)', fontsize=12)\n",
        "ax.set_ylabel('Test Accuracy (%)', fontsize=12)\n",
        "ax.set_title('Robustness Analysis: Performance vs Noise Level', fontsize=14, fontweight='bold')\n",
        "ax.legend(fontsize=11)\n",
        "ax.grid(True, alpha=0.3)\n",
        "ax.set_ylim([0, max(accuracies) + 5])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(args.outdir, 'robustness_analysis.png'), dpi=150, bbox_inches='tight')\n",
        "print(f\"\\n‚úì Robustness analysis saved to {args.outdir}/robustness_analysis.png\")\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"KEY INSIGHTS\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"‚úì Clean accuracy (œÉ=0): {accuracies[0]:.2f}%\")\n",
        "print(f\"‚úì Accuracy at training noise (œÉ={args.noise_sd}): {accuracies[noise_levels.index(args.noise_sd)]:.2f}%\")\n",
        "print(f\"‚úì Accuracy degradation at œÉ=0.50: {accuracies[0] - accuracies[noise_levels.index(0.50)]:.2f}%\")\n",
        "print(f\"‚úì Model shows {'good' if accuracies[noise_levels.index(args.noise_sd)] > 40 else 'limited'} robustness to noise\")\n",
        "print(f\"{'='*60}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0605ab3",
      "metadata": {
        "id": "d0605ab3"
      },
      "source": [
        "## Step 16: Model Prediction Examples\n",
        "\n",
        "Visualize some test samples with predictions and confidence scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "af4863a1",
      "metadata": {
        "id": "af4863a1"
      },
      "outputs": [],
      "source": [
        "# ===== ImageNet Class Names (Active) =====\n",
        "# Get ImageNet class names (using class indices)\n",
        "imagenet_classes = train_dataset.classes  # Gets class folder names (e.g., 'n01440764')\n",
        "\n",
        "# For human-readable names, you can create a mapping or use a pre-made dictionary\n",
        "# Here we'll just use the class indices for visualization\n",
        "def get_class_name(class_idx):\n",
        "    \"\"\"Get readable class name for ImageNet class index.\"\"\"\n",
        "    if class_idx < len(imagenet_classes):\n",
        "        return imagenet_classes[class_idx]\n",
        "    return f\"Class_{class_idx}\"\n",
        "\n",
        "# ===== CIFAR-100 Class Names (Commented Out) =====\n",
        "# cifar100_fine_labels = [\n",
        "#     'apple', 'aquarium_fish', 'baby', 'bear', 'beaver', 'bed', 'bee', 'beetle',\n",
        "#     'bicycle', 'bottle', 'bowl', 'boy', 'bridge', 'bus', 'butterfly', 'camel',\n",
        "#     'can', 'castle', 'caterpillar', 'cattle', 'chair', 'chimpanzee', 'clock',\n",
        "#     'cloud', 'cockroach', 'couch', 'crab', 'crocodile', 'cup', 'dinosaur',\n",
        "#     'dolphin', 'elephant', 'flatfish', 'forest', 'fox', 'girl', 'hamster',\n",
        "#     'house', 'kangaroo', 'keyboard', 'lamp', 'lawn_mower', 'leopard', 'lion',\n",
        "#     'lizard', 'lobster', 'man', 'maple_tree', 'motorcycle', 'mountain', 'mouse',\n",
        "#     'mushroom', 'oak_tree', 'orange', 'orchid', 'otter', 'palm_tree', 'pear',\n",
        "#     'pickup_truck', 'pine_tree', 'plain', 'plate', 'poppy', 'porcupine',\n",
        "#     'possum', 'rabbit', 'raccoon', 'ray', 'road', 'rocket', 'rose',\n",
        "#     'sea', 'seal', 'shark', 'shrew', 'skunk', 'skyscraper', 'snail', 'snake',\n",
        "#     'spider', 'squirrel', 'streetcar', 'sunflower', 'sweet_pepper', 'table',\n",
        "#     'tank', 'telephone', 'television', 'tiger', 'tractor', 'train', 'trout',\n",
        "#     'tulip', 'turtle', 'wardrobe', 'whale', 'willow_tree', 'wolf', 'woman', 'worm'\n",
        "# ]\n",
        "#\n",
        "# def get_class_name(class_idx):\n",
        "#     \"\"\"Get readable class name for CIFAR-100 class index.\"\"\"\n",
        "#     if class_idx < len(cifar100_fine_labels):\n",
        "#         return cifar100_fine_labels[class_idx]\n",
        "#     return f\"Class_{class_idx}\"\n",
        "\n",
        "# Get some test samples\n",
        "model.eval()\n",
        "num_samples = 12\n",
        "\n",
        "# Get a batch from test set\n",
        "dataiter = iter(test_loader)\n",
        "images, labels = next(dataiter)\n",
        "images = images[:num_samples].to(device)\n",
        "labels = labels[:num_samples]\n",
        "\n",
        "# Make predictions\n",
        "with torch.no_grad():\n",
        "    # Add noise\n",
        "    noisy_images = images + torch.randn_like(images) * args.noise_sd\n",
        "    outputs = model(noisy_images)\n",
        "    probs = torch.softmax(outputs, dim=1)\n",
        "    confidences, predictions = probs.max(1)\n",
        "\n",
        "# ===== ImageNet Denormalization (Active) =====\n",
        "# Denormalize images for visualization\n",
        "mean = torch.tensor([0.485, 0.456, 0.406]).view(3, 1, 1).to(device)\n",
        "std = torch.tensor([0.229, 0.224, 0.225]).view(3, 1, 1).to(device)\n",
        "images_denorm = images * std + mean\n",
        "images_denorm = torch.clamp(images_denorm, 0, 1)\n",
        "\n",
        "# ===== CIFAR-100 Denormalization (Commented Out) =====\n",
        "# # Denormalize images for visualization\n",
        "# mean = torch.tensor([0.5071, 0.4867, 0.4408]).view(3, 1, 1).to(device)\n",
        "# std = torch.tensor([0.2675, 0.2565, 0.2761]).view(3, 1, 1).to(device)\n",
        "# images_denorm = images * std + mean\n",
        "# images_denorm = torch.clamp(images_denorm, 0, 1)\n",
        "\n",
        "# Visualize predictions\n",
        "fig, axes = plt.subplots(3, 4, figsize=(16, 12))\n",
        "axes = axes.flatten()\n",
        "\n",
        "for idx in range(num_samples):\n",
        "    ax = axes[idx]\n",
        "\n",
        "    # Convert to numpy and transpose for plotting\n",
        "    img = images_denorm[idx].cpu().permute(1, 2, 0).numpy()\n",
        "\n",
        "    true_label = labels[idx].item()\n",
        "    pred_label = predictions[idx].item()\n",
        "    confidence = confidences[idx].item()\n",
        "\n",
        "    # Plot image\n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "\n",
        "    # Set title with color based on correctness\n",
        "    is_correct = true_label == pred_label\n",
        "    color = 'green' if is_correct else 'red'\n",
        "    marker = '‚úì' if is_correct else '‚úó'\n",
        "\n",
        "    title = f\"{marker} True: {get_class_name(true_label)}\\n\"\n",
        "    title += f\"Pred: {get_class_name(pred_label)}\\n\"\n",
        "    title += f\"Conf: {confidence:.2%}\"\n",
        "\n",
        "    ax.set_title(title, fontsize=10, color=color, fontweight='bold')\n",
        "\n",
        "plt.suptitle('Sample Predictions with Randomized Smoothing', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.savefig(os.path.join(args.outdir, 'sample_predictions.png'), dpi=150, bbox_inches='tight')\n",
        "print(f\"‚úì Sample predictions saved to {args.outdir}/sample_predictions.png\")\n",
        "plt.show()\n",
        "\n",
        "# Print summary\n",
        "correct_in_sample = (predictions.cpu() == labels).sum().item()\n",
        "print(f\"\\nüìä Sample Batch Statistics:\")\n",
        "print(f\"  Correct: {correct_in_sample}/{num_samples} ({100*correct_in_sample/num_samples:.1f}%)\")\n",
        "print(f\"  Average confidence: {confidences.mean().item():.2%}\")\n",
        "print(f\"  Min confidence: {confidences.min().item():.2%}\")\n",
        "print(f\"  Max confidence: {confidences.max().item():.2%}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0125076b",
      "metadata": {
        "id": "0125076b"
      },
      "source": [
        "## Step 17: Generate Comprehensive Evaluation Report\n",
        "\n",
        "Create a summary report of all evaluation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "07a696da",
      "metadata": {
        "id": "07a696da"
      },
      "outputs": [],
      "source": [
        "# Generate comprehensive evaluation report\n",
        "report_path = os.path.join(args.outdir, 'evaluation_report.txt')\n",
        "\n",
        "with open(report_path, 'w') as f:\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"CIFAR-100 RANDOMIZED SMOOTHING CLASSIFIER - EVALUATION REPORT\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\\n\")\n",
        "\n",
        "    f.write(\"MODEL CONFIGURATION\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Architecture: ResNet-18 (standard ImageNet)\\n\")\n",
        "    f.write(f\"Dataset: ImageNet (1000 classes, 224√ó224 images)\\n\")\n",
        "    f.write(f\"Training epochs: {checkpoint['epoch']}\\n\")\n",
        "    f.write(f\"Batch size: {args.batch}\\n\")\n",
        "    f.write(f\"Randomized smoothing noise (œÉ): {args.noise_sd}\\n\\n\")\n",
        "\n",
        "    f.write(\"OVERALL PERFORMANCE METRICS\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Test Accuracy: {eval_results['accuracy']:.2f}%\\n\")\n",
        "    f.write(f\"Correct Predictions: {eval_results['correct']}/{eval_results['total']}\\n\")\n",
        "    f.write(f\"Macro Precision: {eval_results['macro_precision']:.4f}\\n\")\n",
        "    f.write(f\"Macro Recall: {eval_results['macro_recall']:.4f}\\n\")\n",
        "    f.write(f\"Macro F1-Score: {eval_results['macro_f1']:.4f}\\n\\n\")\n",
        "\n",
        "    f.write(\"PERFORMANCE CHARACTERISTICS\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Average Inference Time: {eval_results['avg_inference_time_ms']:.2f} ms per batch\\n\")\n",
        "    f.write(f\"Throughput: {args.batch / (eval_results['avg_inference_time_ms']/1000):.1f} images/sec\\n\")\n",
        "    f.write(f\"Per-class accuracy (mean): {per_class_accuracy.mean():.2f}%\\n\")\n",
        "    f.write(f\"Per-class accuracy (std): {per_class_accuracy.std():.2f}%\\n\")\n",
        "    f.write(f\"Best class accuracy: {per_class_accuracy.max():.2f}% (Class {per_class_accuracy.argmax()})\\n\")\n",
        "    f.write(f\"Worst class accuracy: {per_class_accuracy.min():.2f}% (Class {per_class_accuracy.argmin()})\\n\\n\")\n",
        "\n",
        "    f.write(\"ROBUSTNESS ANALYSIS\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    f.write(f\"Model trained with Gaussian noise œÉ = {args.noise_sd}\\n\")\n",
        "    f.write(f\"Performance at different noise levels:\\n\")\n",
        "    for noise_sd, acc in zip(noise_levels, accuracies):\n",
        "        marker = \" (training level)\" if noise_sd == args.noise_sd else \"\"\n",
        "        f.write(f\"  œÉ = {noise_sd:.2f}: {acc:.2f}%{marker}\\n\")\n",
        "    f.write(f\"\\nClean accuracy (œÉ=0): {accuracies[0]:.2f}%\\n\")\n",
        "    f.write(f\"Accuracy degradation at œÉ=0.50: {accuracies[0] - accuracies[noise_levels.index(0.50)]:.2f}%\\n\\n\")\n",
        "\n",
        "    f.write(\"TOP 5 BEST PERFORMING CLASSES\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    for i, cls in enumerate(best_classes[:5], 1):\n",
        "        f.write(f\"{i}. Class {cls} ({get_class_name(cls)}): {per_class_accuracy[cls]:.2f}%\\n\")\n",
        "\n",
        "    f.write(\"\\nTOP 5 WORST PERFORMING CLASSES\\n\")\n",
        "    f.write(\"-\"*80 + \"\\n\")\n",
        "    for i, cls in enumerate(worst_classes[:5], 1):\n",
        "        f.write(f\"{i}. Class {cls} ({get_class_name(cls)}): {per_class_accuracy[cls]:.2f}%\\n\")\n",
        "\n",
        "    f.write(\"\\n\" + \"=\"*80 + \"\\n\")\n",
        "    f.write(\"CERTIFICATION CAPABILITY\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "    f.write(\"This model has been trained with randomized smoothing, which provides\\n\")\n",
        "    f.write(\"PROVABLE adversarial robustness guarantees. The model can certify predictions\\n\")\n",
        "    f.write(\"within a certified radius around input samples.\\n\\n\")\n",
        "    f.write(\"For certification, use the certify.py script with this trained model.\\n\")\n",
        "    f.write(\"=\"*80 + \"\\n\")\n",
        "\n",
        "print(f\"\\n{'='*80}\")\n",
        "print(\"EVALUATION COMPLETE\")\n",
        "print(f\"{'='*80}\\n\")\n",
        "print(f\"‚úì Comprehensive evaluation report saved to: {report_path}\")\n",
        "print(f\"‚úì Confusion matrix saved to: {os.path.join(args.outdir, 'confusion_matrix.png')}\")\n",
        "print(f\"‚úì Per-class accuracy analysis saved to: {os.path.join(args.outdir, 'per_class_accuracy.png')}\")\n",
        "print(f\"‚úì Robustness analysis saved to: {os.path.join(args.outdir, 'robustness_analysis.png')}\")\n",
        "print(f\"‚úì Sample predictions saved to: {os.path.join(args.outdir, 'sample_predictions.png')}\")\n",
        "print(f\"\\nüìä Summary:\")\n",
        "print(f\"   Test Accuracy: {eval_results['accuracy']:.2f}%\")\n",
        "print(f\"   Macro F1-Score: {eval_results['macro_f1']:.4f}\")\n",
        "print(f\"   Robustness: Model maintains {accuracies[noise_levels.index(args.noise_sd)]:.2f}% accuracy at training noise level\")\n",
        "print(f\"\\n{'='*80}\\n\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}